{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e44842",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os                             # íŒŒì¼ ë° ë””ë ‰í† ë¦¬ ì‘ì—…ì„ ìœ„í•œ ëª¨ë“ˆ\n",
    "import torch                          # PyTorch ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬\n",
    "import torch.nn as nn                 # ì‹ ê²½ë§ ê´€ë ¨ ëª¨ë“ˆ\n",
    "import torch.optim as optim           # ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ëª¨ë“ˆ\n",
    "from PIL import Image                 # ì´ë¯¸ì§€ ì²˜ë¦¬ ëª¨ë“ˆ (Pillow)\n",
    "import shutil                         # íŒŒì¼ ë° í´ë” ë³µì‚¬/ì‚­ì œ ë“±ì„ ìœ„í•œ ê³ ê¸‰ íŒŒì¼ ì²˜ë¦¬ ëª¨ë“ˆ\n",
    "from torchvision import transforms, models  # ì´ë¯¸ì§€ ë³€í™˜ ë° ì‚¬ì „í•™ìŠµ ëª¨ë¸\n",
    "from torch.utils.data import Dataset, DataLoader  # ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ë° ë°°ì¹˜ ë¡œë”\n",
    "import matplotlib.pyplot as plt       # ê·¸ë˜í”„ ì‹œê°í™”\n",
    "from IPython.display import clear_output  # Jupyter Notebookì—ì„œ ì¶œë ¥ ê°±ì‹ ìš©\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •: GPUê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° 'cuda', ì•„ë‹ˆë©´ 'cpu'ë¥¼ ì‚¬ìš©\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ì‚­ì œí•  í´ë” ê²½ë¡œ ì§€ì •\n",
    "folder_path = \"checkpoints/train/weights\"\n",
    "\n",
    "# í•´ë‹¹ í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "if os.path.exists(folder_path):\n",
    "    # í´ë” ì•ˆì˜ ëª¨ë“  íŒŒì¼ê³¼ í•˜ìœ„ í´ë”ë¥¼ ìˆœíšŒ\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # ê° íŒŒì¼ ë˜ëŠ” í´ë”ì˜ ì „ì²´ ê²½ë¡œë¥¼ ìƒì„±\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            # í•´ë‹¹ ê²½ë¡œê°€ 'íŒŒì¼' ë˜ëŠ” 'ì‹¬ë³¼ë¦­ ë§í¬'ì¸ ê²½ìš° ì‚­ì œ\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # íŒŒì¼ ë˜ëŠ” ë§í¬ ì‚­ì œ\n",
    "                print(f\"íŒŒì¼ '{file_path}'ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            # í•´ë‹¹ ê²½ë¡œê°€ 'ë””ë ‰í† ë¦¬'ì¸ ê²½ìš° ì¬ê·€ì ìœ¼ë¡œ ì‚­ì œ\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # í´ë” ì „ì²´ ì‚­ì œ\n",
    "                print(f\"í´ë” '{file_path}'ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        except Exception as e:\n",
    "            # ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì¶œë ¥\n",
    "            print(f\"'{file_path}'ë¥¼ ì‚­ì œí•˜ëŠ” ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
    "else:\n",
    "    # í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€ ì¶œë ¥\n",
    "    print(f\"í´ë” '{folder_path}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e885a64",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "EPOCH = 20        # ì´ í•™ìŠµ ì—í¬í¬ ìˆ˜\n",
    "pre_epoch = 0      # ì‹œì‘ ì—í¬í¬ (ì¬í•™ìŠµ ì‹œ ì‚¬ìš©)\n",
    "BATCH_SIZE = 16    # ë°°ì¹˜ í¬ê¸°\n",
    "LR = 0.01          # í•™ìŠµë¥ \n",
    "TRAIN_DATA_PERCENT = 0.8  # í›ˆë ¨ ë°ì´í„° ë¹„ìœ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b187b58",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# PyTorchì˜ Dataset í´ë˜ìŠ¤ë¥¼ ìƒì†í•˜ì—¬ CustomDataset ì •ì˜\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir                    # ë°ì´í„°ì…‹ì˜ ë£¨íŠ¸ í´ë” ê²½ë¡œ\n",
    "        self.transform = transform                  # ì´ë¯¸ì§€ì— ì ìš©í•  ë³€í™˜(transform) í•¨ìˆ˜\n",
    "        # í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ë¥¼ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì €ì¥\n",
    "        self.classes = sorted([\n",
    "            d for d in os.listdir(root_dir)\n",
    "            if os.path.isdir(os.path.join(root_dir, d))  # í´ë”ë§Œ ì¶”ì¶œ\n",
    "        ])\n",
    "        # í´ë˜ìŠ¤ ì´ë¦„ì„ ìˆ«ì ì¸ë±ìŠ¤ë¡œ ë§¤í•‘ (ì˜ˆ: {'cat': 0, 'dog': 1})\n",
    "        self.class_to_idx = {\n",
    "            cls_name: idx for idx, cls_name in enumerate(self.classes)\n",
    "        }\n",
    "        # ëª¨ë“  ì´ë¯¸ì§€ ê²½ë¡œì™€ ë¼ë²¨ì„ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜ í˜¸ì¶œ\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        data = []\n",
    "        for cls in self.classes:\n",
    "            class_path = os.path.join(self.root_dir, cls)  # í´ë˜ìŠ¤ë³„ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "            for img_name in os.listdir(class_path):        # í´ë˜ìŠ¤ í´ë” ì•ˆì˜ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                label = self.class_to_idx[cls]              # í´ë˜ìŠ¤ ì´ë¦„ì„ ìˆ«ìë¡œ ë§¤í•‘\n",
    "                data.append((img_path, label))              # (ì´ë¯¸ì§€ ê²½ë¡œ, ë¼ë²¨) íŠœí”Œ ì €ì¥\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # ì „ì²´ ë°ì´í„° ê°œìˆ˜ ë°˜í™˜\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]                    # ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œì™€ ë¼ë²¨\n",
    "        image = Image.open(img_path).convert('RGB')         # ì´ë¯¸ì§€ íŒŒì¼ ì—´ê³  RGBë¡œ ë³€í™˜\n",
    "        if self.transform:                                  # transformì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì ìš©\n",
    "            image = self.transform(image)\n",
    "        return image, label                                 # ì´ë¯¸ì§€ì™€ ë¼ë²¨ ë°˜í™˜\n",
    "\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬ ì„¤ì •: ì´ë¯¸ì§€ë¥¼ 224x224 í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•˜ê³  í…ì„œë¡œ ë³€í™˜\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   # ì…ë ¥ í¬ê¸°ë¥¼ ì‚¬ì „í•™ìŠµ ëª¨ë¸ í¬ê¸°ì— ë§ì¶¤\n",
    "    transforms.ToTensor()            # [0, 1] ë²”ìœ„ì˜ Tensorë¡œ ë³€í™˜\n",
    "])\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ (ì˜ˆ: 'data' í´ë” êµ¬ì¡°ëŠ” data/class1/*.jpg, data/class2/*.jpg ...)\n",
    "dataset = CustomDataset(root_dir=\"data\", transform=transform)\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ì…‹ì—ì„œ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¹„ìœ¨ ì„¤ì •\n",
    "# ì˜ˆ: TRAIN_DATA_PERCENT = 0.8ì´ë¼ë©´ í›ˆë ¨ 80%, í…ŒìŠ¤íŠ¸ 20%\n",
    "train_size = int(TRAIN_DATA_PERCENT * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# ë°ì´í„°ì…‹ì„ ë¬´ì‘ìœ„ë¡œ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• \n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoaderëŠ” ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¶ˆëŸ¬ì˜¤ê³ , ë©€í‹° ìŠ¤ë ˆë”©(num_workers)ì„ í™œìš©\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì˜ í¬ê¸° ì¶œë ¥\n",
    "print(f\"í›ˆë ¨ ë°ì´í„° ìˆ˜: {len(train_dataset)}, í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd86eff0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# í´ë˜ìŠ¤ ìˆ˜ í™•ì¸\n",
    "classes = dataset.classes        # ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì—ì„œ í´ë˜ìŠ¤ ì´ë¦„ ëª©ë¡ ì¶”ì¶œ\n",
    "NUM_CLASSES = len(classes)       # ì „ì²´ í´ë˜ìŠ¤ ìˆ˜ ê³„ì‚° (ì˜ˆ: 3ê°œ í´ë˜ìŠ¤ë©´ 3)\n",
    "\n",
    "# ì‚¬ì „ í•™ìŠµëœ ResNet-18 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "net = models.resnet50()          # torchvisionì—ì„œ ResNet-18 ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ì ìœ¼ë¡œ pretrained=False)\n",
    "\n",
    "# ëª¨ë¸ì˜ ë§ˆì§€ë§‰ fully connected layer ì…ë ¥ íŠ¹ì§• ìˆ˜ í™•ì¸\n",
    "num_ftrs = net.fc.in_features    # ê¸°ì¡´ FC layerì— ë“¤ì–´ê°€ëŠ” ì…ë ¥ ë‰´ëŸ° ìˆ˜ (ì˜ˆ: 512)\n",
    "\n",
    "# ë§ˆì§€ë§‰ FC layerë¥¼ í˜„ì¬ ë¬¸ì œì— ë§ê²Œ ì»¤ìŠ¤í„°ë§ˆì´ì§•\n",
    "# ì›ë˜ëŠ” ImageNet ê¸°ì¤€ 1000ê°œ í´ë˜ìŠ¤ì˜€ì§€ë§Œ, ìš°ë¦¬ëŠ” NUM_CLASSESì— ë§ê²Œ ì¡°ì •\n",
    "net.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "\n",
    "# ëª¨ë¸ì„ CUDA(GPU) ë˜ëŠ” CPUë¡œ ì´ë™ (ì•ì—ì„œ ì„¤ì •í•œ deviceì— ë”°ë¼)\n",
    "net = net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12910b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì •ì˜\n",
    "\n",
    "# ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ì†ì‹¤ í•¨ìˆ˜: CrossEntropyLoss\n",
    "# softmaxì™€ negative log likelihoodë¥¼ í•¨ê»˜ ìˆ˜í–‰í•¨\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•(SGD)ì„ ì‚¬ìš©í•œ ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
    "# - net.parameters(): í•™ìŠµí•  ëª¨ë¸ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°\n",
    "# - lr: í•™ìŠµë¥  (learning rate), ë„ˆë¬´ í¬ë©´ ë°œì‚°í•˜ê³ , ë„ˆë¬´ ì‘ìœ¼ë©´ ìˆ˜ë ´ì´ ëŠë¦¼\n",
    "# - momentum: ê´€ì„± í•­ìœ¼ë¡œ, ì´ì „ì˜ ì—…ë°ì´íŠ¸ ë°©í–¥ì„ ì¼ë¶€ ë°˜ì˜í•˜ì—¬ ìµœì í™”ì˜ ì†ë„ë¥¼ ë†’ì„\n",
    "# - weight_decay: L2 ì •ê·œí™” ê³„ìˆ˜ë¡œ ê³¼ì í•©ì„ ë°©ì§€í•¨\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918d2b6f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "train_losses = []       # ê° ì—í­(epoch)ë§ˆë‹¤ì˜ í‰ê·  í›ˆë ¨ ì†ì‹¤(loss)ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "train_accuracies = []   # ê° ì—í­ë§ˆë‹¤ì˜ í›ˆë ¨ ì •í™•ë„(accuracy)ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "test_accuracies = []    # ê° ì—í­ë§ˆë‹¤ì˜ í…ŒìŠ¤íŠ¸ ì •í™•ë„ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "# í›ˆë ¨ ë£¨í”„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì „ì²´ í›ˆë ¨ì€ ì§€ì •ëœ ì—í­ ìˆ˜(EPOCH)ë§Œí¼ ë°˜ë³µë©ë‹ˆë‹¤.\n",
    "for epoch in range(EPOCH):\n",
    "    print(f'\\nğŸ” ì—í­: {epoch + 1}')  # í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì—í­ ë²ˆí˜¸ë¥¼ ì¶œë ¥\n",
    "    net.train()  # ëª¨ë¸ì„ í›ˆë ¨ ëª¨ë“œë¡œ ì„¤ì • (Dropout, BatchNorm ë“±ì˜ ë™ì‘ ë°©ì‹ì´ ë³€ê²½ë¨)\n",
    "\n",
    "    sum_loss = 0.0  # í•œ ì—í­ ë™ì•ˆì˜ ì „ì²´ ì†ì‹¤ ê°’ì„ ëˆ„ì í•  ë³€ìˆ˜\n",
    "    correct = 0     # ì •í™•íˆ ì˜ˆì¸¡í•œ ìƒ˜í”Œ ê°œìˆ˜ ì´ˆê¸°í™”\n",
    "    total = 0       # ì „ì²´ ìƒ˜í”Œ ê°œìˆ˜ ì´ˆê¸°í™”\n",
    "\n",
    "    # í›ˆë ¨ ë°ì´í„°ì…‹ì„ í•˜ë‚˜ì”© ë°˜ë³µí•˜ë©° í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data  # ë°ì´í„°ë¡œë¶€í„° ì…ë ¥ ì´ë¯¸ì§€ì™€ ì •ë‹µ ë ˆì´ë¸”ì„ ë¶„ë¦¬\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # GPU ë˜ëŠ” CPUë¡œ ë°ì´í„° ì´ë™\n",
    "\n",
    "        optimizer.zero_grad()  # ì´ì „ ë°°ì¹˜ì—ì„œ ê³„ì‚°ëœ ê¸°ìš¸ê¸° ì •ë³´ë¥¼ ì´ˆê¸°í™”\n",
    "\n",
    "        outputs = net(inputs)              # ëª¨ë¸ì— ì…ë ¥ê°’ì„ ë„£ì–´ ì˜ˆì¸¡ê°’(ì¶œë ¥)ì„ ì–»ìŒ\n",
    "        loss = criterion(outputs, labels)  # ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ì‚¬ì´ì˜ ì†ì‹¤ì„ ê³„ì‚°\n",
    "        loss.backward()                    # ì†ì‹¤ì„ ê¸°ì¤€ìœ¼ë¡œ ì—­ì „íŒŒ ìˆ˜í–‰ (ê¸°ìš¸ê¸° ê³„ì‚°)\n",
    "        optimizer.step()                   # ê³„ì‚°ëœ ê¸°ìš¸ê¸°ë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
    "\n",
    "        sum_loss += loss.item()  # ì†ì‹¤ ê°’ì„ ëˆ„ì í•˜ì—¬ í‰ê·  ê³„ì‚°ì— ì‚¬ìš©\n",
    "        _, predicted = torch.max(outputs.data, 1)  # ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ì¤‘ ê°€ì¥ í™•ë¥  ë†’ì€ ê°’ ì„ íƒ\n",
    "        total += labels.size(0)  # ì „ì²´ ìƒ˜í”Œ ê°œìˆ˜ ëˆ„ì \n",
    "        correct += predicted.eq(labels.data).sum().item()  # ì •ë‹µê³¼ ì¼ì¹˜í•œ ì˜ˆì¸¡ ê°œìˆ˜ ëˆ„ì \n",
    "\n",
    "    # í•œ ì—í­ì˜ í‰ê·  ì†ì‹¤ê³¼ ì •í™•ë„ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
    "    train_losses.append(sum_loss / len(train_loader))\n",
    "    train_accuracies.append(100. * correct / total)\n",
    "\n",
    "    # í˜„ì¬ê¹Œì§€ í•™ìŠµëœ ëª¨ë¸ì„ TorchScript í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ì¶”ë¡  ìµœì í™” ë° ë°°í¬ ìš©ì´)\n",
    "    model_scripted = torch.jit.script(net)\n",
    "    model_scripted.save(os.path.join('checkpoints/train/weights', f'resnet_{epoch + 1}.pt'))\n",
    "\n",
    "    # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    print('ğŸ§ª í…ŒìŠ¤íŠ¸ ì§„í–‰ ì¤‘...')\n",
    "    net.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (Dropout ë¹„í™œì„±í™” ë“±)\n",
    "    with torch.no_grad():  # í…ŒìŠ¤íŠ¸ ì‹œì—ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ì§€ ì•Šì•„ ë©”ëª¨ë¦¬ ì ˆì•½\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels.data).sum().item()\n",
    "\n",
    "    test_accuracy = 100. * correct / total  # í…ŒìŠ¤íŠ¸ ì •í™•ë„ ê³„ì‚°\n",
    "    test_accuracies.append(test_accuracy)   # ë¦¬ìŠ¤íŠ¸ì— ê¸°ë¡\n",
    "\n",
    "    # í›ˆë ¨ ì¤‘ ì‹¤ì‹œê°„ìœ¼ë¡œ ì†ì‹¤ ë° ì •í™•ë„ ê·¸ë˜í”„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # ğŸŸ  í›ˆë ¨ ì†ì‹¤ ê·¸ë˜í”„\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, epoch + 2), train_losses, marker='o', label='Train Loss')\n",
    "    plt.title('Train Loss')\n",
    "    plt.xlabel('Epoch')  # ì—í­ ìˆ˜\n",
    "    plt.ylabel('Loss')   # ì†ì‹¤ ê°’\n",
    "    plt.legend()\n",
    "\n",
    "    # ğŸ”µ í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ì •í™•ë„ ê·¸ë˜í”„\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epoch + 2), train_accuracies, marker='o', label='Train Accuracy')\n",
    "    plt.plot(range(1, epoch + 2), test_accuracies, marker='o', label='Test Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')  # ì—í­ ìˆ˜\n",
    "    plt.ylabel('%')      # ì •í™•ë„ ë¹„ìœ¨\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()  # ê·¸ë˜í”„ ê°„ê²©ì„ ìë™ ì¡°ì •\n",
    "    plt.show()\n",
    "\n",
    "    # í˜„ì¬ ì—í­ì˜ í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶œë ¥\n",
    "    print(f'[ì—í­ {epoch + 1}] í›ˆë ¨ ì†ì‹¤: {train_losses[-1]:.3f} | '\n",
    "          f'í›ˆë ¨ ì •í™•ë„: {train_accuracies[-1]:.2f}% | '\n",
    "          f'í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracies[-1]:.2f}%')\n",
    "\n",
    "# ëª¨ë“  í›ˆë ¨ ì—í­ì´ ì™„ë£Œë˜ì—ˆìŒì„ ì•Œë¦¬ëŠ” ë©”ì‹œì§€ ì¶œë ¥\n",
    "print(f'\\nâœ… í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì—í­ ìˆ˜: {EPOCH}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
